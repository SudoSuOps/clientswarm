# SwarmOS Backend Architecture

## Overview

SwarmOS is sovereign compute infrastructure. This document defines the backend systems that power job execution, settlement, and epoch finalization.

```
Client Request â†’ Bee-1 (Controller) â†’ SwarmRails (Queue) â†’ Bee-2 (Worker) â†’ Result â†’ Epoch â†’ SwarmOrb
```

---

## ENS Identity Map

| ENS | Role | Subdomain Pattern |
|-----|------|-------------------|
| `swarmos.eth` | Controller / Queen | `api.swarmos.eth`, `ledger.swarmos.eth` |
| `swarmbee.eth` | Workers | `bee-01.swarmbee.eth`, `bee-02.swarmbee.eth` |
| `swarmepoch.eth` | Ledger / Settlement | `data.swarmepoch.eth` |
| `swarmorb.eth` | Explorer | `swarmorb.eth.limo` |
| `swarmbank.eth` | Treasury | `vault.swarmbank.eth` |
| `clientswarm.eth` | Clients | `xyzclinic.clientswarm.eth` |

---

## Component Breakdown

### 1. Bee-1 (Controller)

**Location:** `api.swarmos.eth` (resolves to your server IP)

**Responsibilities:**
- Receive signed job requests from clients
- Verify EIP-191 signatures + ENS ownership
- Check client USDC balance
- Create job records in ledger
- Queue jobs for workers
- Route jobs to available workers
- Receive results from workers
- Update ledger with completion
- Deduct client balance
- Trigger epoch sealing

**Tech Stack:**
- Python 3.11+ / FastAPI
- Async everywhere
- Pydantic for validation
- SQLAlchemy for ORM

### 2. Bee-2...N (Workers)

**Location:** `bee-XX.swarmbee.eth` (LAN IPs, not public)

**Responsibilities:**
- Register with Bee-1 on startup
- Send heartbeats every 30s
- Pull jobs from queue
- Execute MONAI inference
- Generate Proof of Execution (PoE) hash
- Return results to Bee-1
- Report hardware stats (GPU, VRAM, utilization)

**Tech Stack:**
- Python 3.11+
- MONAI for medical imaging
- PyTorch + CUDA
- gRPC or HTTP for communication

### 3. SwarmRails (Queue)

**Responsibilities:**
- Job queue (pending â†’ processing â†’ complete)
- Worker registry (online, busy, offline)
- Job routing logic (round-robin, least-busy, GPU-match)
- Dead letter queue for failed jobs
- Retry logic

**Tech Stack:**
- Redis (simple, fast, proven)
- Redis Streams for job queue
- Redis Pub/Sub for worker events

### 4. SwarmLedger (Database)

**Responsibilities:**
- Job records (immutable after completion)
- Epoch records
- Client accounts
- Worker registry
- Payout history

**Tech Stack:**
- SQLite for simplicity (â†’ Postgres for scale)
- SQLAlchemy ORM
- Alembic for migrations

### 5. SwarmBank (Treasury)

**Responsibilities:**
- Client USDC balances
- Credit top-ups (watch L1 for transfers)
- Balance deductions on job complete
- Payout calculations (Work Pool 70%, Readiness Pool 30%)
- Operator fee (5%), Protocol fee (2%)

**Tech Stack:**
- Web3.py for L1 interaction
- USDC contract monitoring
- Internal balance ledger (off-chain for speed)
- On-chain settlement for withdrawals

### 6. Epoch Sealer (Scheduled Job)

**Responsibilities:**
- Run every 24 hours (or on-demand)
- Collect all completed jobs in epoch
- Compute Merkle root over jobs
- Generate SUMMARY.json
- Generate SIGNATURE.txt (EIP-191 signed by swarmos.eth)
- Calculate payouts per worker
- Pin epoch bundle to IPFS
- Trigger SwarmOrb index update

**Tech Stack:**
- Python script (cron or systemd timer)
- Merkle tree implementation
- eth_account for signing
- IPFS HTTP API for pinning

---

## Data Flow

### Job Submission Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CLIENT SUBMITS JOB                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Client (xyz.clientswarm.eth)                                   â”‚
â”‚     â”‚                                                           â”‚
â”‚     â”‚ POST /api/v1/jobs                                         â”‚
â”‚     â”‚ {                                                         â”‚
â”‚     â”‚   "job_type": "spine_mri",                               â”‚
â”‚     â”‚   "dicom_ref": "ipfs://Qm...",                           â”‚
â”‚     â”‚   "client_ens": "xyz.clientswarm.eth",                   â”‚
â”‚     â”‚   "signature": "0x...",                                   â”‚
â”‚     â”‚   "timestamp": 1704067200                                 â”‚
â”‚     â”‚ }                                                         â”‚
â”‚     â–¼                                                           â”‚
â”‚  Bee-1 API (api.swarmos.eth)                                   â”‚
â”‚     â”‚                                                           â”‚
â”‚     â”œâ”€â–º Verify signature (EIP-191)                             â”‚
â”‚     â”œâ”€â–º Verify ENS ownership                                    â”‚
â”‚     â”œâ”€â–º Check balance â‰¥ $0.10                                  â”‚
â”‚     â”œâ”€â–º Create job record (status: pending)                    â”‚
â”‚     â”œâ”€â–º Reserve $0.10 from balance                             â”‚
â”‚     â”œâ”€â–º Queue job in Redis                                      â”‚
â”‚     â”‚                                                           â”‚
â”‚     â–¼                                                           â”‚
â”‚  Return: { "job_id": "job-002-0848", "status": "queued" }      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Job Execution Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. WORKER EXECUTES JOB                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  SwarmRails (Redis)                                             â”‚
â”‚     â”‚                                                           â”‚
â”‚     â”‚ Job available in queue                                    â”‚
â”‚     â–¼                                                           â”‚
â”‚  Bee-2 (bee-01.swarmbee.eth)                                   â”‚
â”‚     â”‚                                                           â”‚
â”‚     â”œâ”€â–º Pull job from queue                                     â”‚
â”‚     â”œâ”€â–º Update status: processing                               â”‚
â”‚     â”œâ”€â–º Download DICOM from IPFS                               â”‚
â”‚     â”œâ”€â–º Run MONAI inference                                     â”‚
â”‚     â”œâ”€â–º Generate result + PoE hash                             â”‚
â”‚     â”‚   PoE = sha256(job_id + result_hash + worker_ens)        â”‚
â”‚     â”œâ”€â–º Upload result to IPFS                                   â”‚
â”‚     â”‚                                                           â”‚
â”‚     â–¼                                                           â”‚
â”‚  POST /api/v1/jobs/{job_id}/complete                           â”‚
â”‚  {                                                              â”‚
â”‚    "result_ref": "ipfs://Qm...",                               â”‚
â”‚    "poe_hash": "abc123...",                                    â”‚
â”‚    "execution_ms": 2847,                                        â”‚
â”‚    "worker_signature": "0x..."                                  â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Job Settlement Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. BEE-1 SETTLES JOB                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Bee-1 receives completion                                      â”‚
â”‚     â”‚                                                           â”‚
â”‚     â”œâ”€â–º Verify worker signature                                 â”‚
â”‚     â”œâ”€â–º Verify PoE hash                                         â”‚
â”‚     â”œâ”€â–º Update job record (status: completed)                  â”‚
â”‚     â”œâ”€â–º Finalize balance deduction ($0.10)                     â”‚
â”‚     â”œâ”€â–º Credit worker for payout (pending epoch)               â”‚
â”‚     â”œâ”€â–º Add job to current epoch batch                         â”‚
â”‚     â”‚                                                           â”‚
â”‚     â–¼                                                           â”‚
â”‚  Job available for client to fetch result                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Epoch Sealing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EPOCH SEALS (Every 24h)                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Epoch Sealer (cron job)                                        â”‚
â”‚     â”‚                                                           â”‚
â”‚     â”œâ”€â–º Collect all completed jobs in epoch                    â”‚
â”‚     â”œâ”€â–º Sort jobs by job_id                                     â”‚
â”‚     â”œâ”€â–º Compute Merkle tree                                     â”‚
â”‚     â”œâ”€â–º Generate SUMMARY.json                                   â”‚
â”‚     â”‚   {                                                       â”‚
â”‚     â”‚     "epoch_id": "epoch-002",                             â”‚
â”‚     â”‚     "jobs_merkle_root": "7ec20e03...",                   â”‚
â”‚     â”‚     "treasury": { ... },                                  â”‚
â”‚     â”‚     "agents": { ... },                                    â”‚
â”‚     â”‚     "clients": { ... }                                    â”‚
â”‚     â”‚   }                                                       â”‚
â”‚     â”œâ”€â–º Generate jobs.json, agents.json                        â”‚
â”‚     â”œâ”€â–º Compute hashes for all artifacts                       â”‚
â”‚     â”œâ”€â–º Sign with swarmos.eth key (EIP-191)                    â”‚
â”‚     â”œâ”€â–º Generate SIGNATURE.txt                                  â”‚
â”‚     â”œâ”€â–º Bundle: audit/epoch-002/                               â”‚
â”‚     â”œâ”€â–º Pin to IPFS                                             â”‚
â”‚     â”œâ”€â–º Calculate payouts:                                      â”‚
â”‚     â”‚   - Work Pool (70%) â†’ per job completed                  â”‚
â”‚     â”‚   - Readiness Pool (30%) â†’ per uptime                    â”‚
â”‚     â”‚   - Protocol Fee (2%) â†’ bee23.eth                        â”‚
â”‚     â”‚   - Operator Fee (5%) â†’ swarmos.eth                      â”‚
â”‚     â”œâ”€â–º Record payouts in ledger                               â”‚
â”‚     â”‚                                                           â”‚
â”‚     â–¼                                                           â”‚
â”‚  Epoch finalized. SwarmOrb indexer picks up new epoch.         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Database Schema

### Jobs Table

```sql
CREATE TABLE jobs (
    id TEXT PRIMARY KEY,              -- job-002-0848
    epoch_id TEXT NOT NULL,           -- epoch-002
    client_ens TEXT NOT NULL,         -- xyz.clientswarm.eth
    worker_ens TEXT,                  -- bee-01.swarmbee.eth
    job_type TEXT NOT NULL,           -- spine_mri
    status TEXT NOT NULL,             -- pending, processing, completed, failed
    dicom_ref TEXT,                   -- ipfs://Qm...
    result_ref TEXT,                  -- ipfs://Qm...
    poe_hash TEXT,                    -- proof of execution
    fee_usd DECIMAL(10,2) DEFAULT 0.10,
    execution_ms INTEGER,
    submitted_at TIMESTAMP NOT NULL,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Epochs Table

```sql
CREATE TABLE epochs (
    id TEXT PRIMARY KEY,              -- epoch-002
    status TEXT NOT NULL,             -- active, sealing, finalized
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP,
    jobs_count INTEGER DEFAULT 0,
    jobs_merkle_root TEXT,
    total_revenue DECIMAL(10,2) DEFAULT 0,
    total_distributed DECIMAL(10,2) DEFAULT 0,
    signature TEXT,                   -- EIP-191 signature
    ipfs_hash TEXT,                   -- Qm...
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Clients Table

```sql
CREATE TABLE clients (
    ens TEXT PRIMARY KEY,             -- xyz.clientswarm.eth
    balance_usd DECIMAL(10,2) DEFAULT 0,
    reserved_usd DECIMAL(10,2) DEFAULT 0,
    total_spent_usd DECIMAL(10,2) DEFAULT 0,
    total_jobs INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Workers Table

```sql
CREATE TABLE workers (
    ens TEXT PRIMARY KEY,             -- bee-01.swarmbee.eth
    status TEXT NOT NULL,             -- online, busy, offline, draining
    gpu_model TEXT,
    vram_gb INTEGER,
    current_job_id TEXT,
    jobs_completed INTEGER DEFAULT 0,
    total_earned_usd DECIMAL(10,2) DEFAULT 0,
    uptime_seconds INTEGER DEFAULT 0,
    last_heartbeat TIMESTAMP,
    registered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Payouts Table

```sql
CREATE TABLE payouts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    epoch_id TEXT NOT NULL,
    worker_ens TEXT NOT NULL,
    work_share_usd DECIMAL(10,2) DEFAULT 0,
    readiness_share_usd DECIMAL(10,2) DEFAULT 0,
    total_payout_usd DECIMAL(10,2) DEFAULT 0,
    jobs_completed INTEGER DEFAULT 0,
    uptime_seconds INTEGER DEFAULT 0,
    status TEXT DEFAULT 'pending',    -- pending, paid
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Credit Transactions Table

```sql
CREATE TABLE credit_transactions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    client_ens TEXT NOT NULL,
    tx_type TEXT NOT NULL,            -- deposit, job_charge, refund
    amount_usd DECIMAL(10,2) NOT NULL,
    balance_after DECIMAL(10,2) NOT NULL,
    reference TEXT,                   -- job_id or tx_hash
    eth_tx_hash TEXT,                 -- L1 transaction hash
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## API Endpoints

### Jobs API

```
POST   /api/v1/jobs                    # Submit new job
GET    /api/v1/jobs/{job_id}           # Get job status
GET    /api/v1/jobs/{job_id}/result    # Get job result
GET    /api/v1/jobs/{job_id}/receipt   # Get Merkle receipt
GET    /api/v1/jobs?client={ens}       # List client jobs
```

### Workers API (Internal)

```
POST   /api/v1/workers/register        # Worker registration
POST   /api/v1/workers/heartbeat       # Worker heartbeat
POST   /api/v1/jobs/{job_id}/claim     # Claim job from queue
POST   /api/v1/jobs/{job_id}/complete  # Submit job completion
```

### Clients API

```
GET    /api/v1/clients/{ens}           # Get client info
GET    /api/v1/clients/{ens}/balance   # Get balance
POST   /api/v1/clients/{ens}/topup     # Record L1 deposit
GET    /api/v1/clients/{ens}/history   # Transaction history
```

### Epochs API

```
GET    /api/v1/epochs                  # List all epochs
GET    /api/v1/epochs/current          # Get current epoch
GET    /api/v1/epochs/{id}             # Get epoch details
GET    /api/v1/epochs/{id}/jobs        # Get epoch jobs
GET    /api/v1/epochs/{id}/payouts     # Get epoch payouts
```

---

## Directory Structure

```
swarmos/
â”œâ”€â”€ bee1/                           # Controller (Bee-1)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs.py             # Job endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ workers.py          # Worker endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ clients.py          # Client endpoints
â”‚   â”‚   â”‚   â””â”€â”€ epochs.py           # Epoch endpoints
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ auth.py             # Signature verification
â”‚   â”‚   â””â”€â”€ deps.py                 # Dependencies
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py               # Settings
â”‚   â”‚   â”œâ”€â”€ queue.py                # Redis queue
â”‚   â”‚   â”œâ”€â”€ router.py               # Job routing
â”‚   â”‚   â””â”€â”€ ledger.py               # DB operations
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ bee2/                           # Worker template (Bee-2...N)
â”‚   â”œâ”€â”€ worker/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # Worker daemon
â”‚   â”‚   â”œâ”€â”€ executor.py             # Job execution
â”‚   â”‚   â”œâ”€â”€ heartbeat.py            # Health reporting
â”‚   â”‚   â””â”€â”€ inference/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ base.py             # Base inference class
â”‚   â”‚       â”œâ”€â”€ spine_mri.py        # Spine analysis
â”‚   â”‚       â””â”€â”€ brain_mri.py        # Brain segmentation
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ rails/                          # Shared libraries
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py               # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ session.py              # DB session
â”‚   â”‚   â””â”€â”€ migrations/             # Alembic migrations
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ redis.py                # Redis client
â”‚   â”œâ”€â”€ crypto/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ens.py                  # ENS resolution
â”‚   â”‚   â”œâ”€â”€ signing.py              # EIP-191 signing
â”‚   â”‚   â””â”€â”€ merkle.py               # Merkle tree
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ job.py                  # Job schemas
â”‚   â”‚   â”œâ”€â”€ epoch.py                # Epoch schemas
â”‚   â”‚   â””â”€â”€ receipt.py              # Receipt schemas
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ ipfs.py                 # IPFS client
â”‚
â”œâ”€â”€ epoch-sealer/                   # Epoch finalization
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sealer.py                   # Main sealer logic
â”‚   â”œâ”€â”€ payout.py                   # Payout calculations
â”‚   â”œâ”€â”€ publisher.py                # IPFS publishing
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ orb-sync/                       # SwarmOrb integration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ indexer.py                  # Generate index.json
â”‚   â””â”€â”€ watcher.py                  # Watch for new epochs
â”‚
â”œâ”€â”€ docker-compose.yml              # Local dev stack
â”œâ”€â”€ docker-compose.prod.yml         # Production stack
â”œâ”€â”€ .env.example
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

---

## Configuration

### Environment Variables

```bash
# Bee-1 Controller
BEE1_HOST=0.0.0.0
BEE1_PORT=8000
BEE1_ENS=swarmos.eth
BEE1_PRIVATE_KEY=0x...           # For signing epochs

# Database
DATABASE_URL=sqlite:///./swarmledger.db
# DATABASE_URL=postgresql://user:pass@localhost/swarmledger

# Redis
REDIS_URL=redis://localhost:6379/0

# IPFS
IPFS_API_URL=http://localhost:5001

# Ethereum L1
ETH_RPC_URL=https://mainnet.infura.io/v3/...
USDC_CONTRACT=0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48

# Epochs
EPOCH_DURATION_HOURS=24
WORK_POOL_PCT=70
READINESS_POOL_PCT=30
PROTOCOL_FEE_PCT=2
OPERATOR_FEE_PCT=5

# Job Pricing
JOB_FEE_USD=0.10
```

---

## Deployment

### Single Rack Setup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      YOUR RACK                               â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Bee-1   â”‚  â”‚ Redis   â”‚  â”‚ SQLite  â”‚  â”‚ IPFS    â”‚       â”‚
â”‚  â”‚ :8000   â”‚  â”‚ :6379   â”‚  â”‚ (file)  â”‚  â”‚ :5001   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚            â”‚            â”‚            â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                         â”‚                                    â”‚
â”‚                    LAN (10.0.0.x)                           â”‚
â”‚                         â”‚                                    â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚       â”‚                 â”‚                 â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Bee-2   â”‚      â”‚ Bee-3   â”‚      â”‚ Bee-N   â”‚            â”‚
â”‚  â”‚ GPU x8  â”‚      â”‚ GPU x8  â”‚      â”‚ GPU x8  â”‚            â”‚
â”‚  â”‚ 5090s   â”‚      â”‚ 6000Ada â”‚      â”‚ 3090s   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                              â”‚
â”‚  SOLAR POWER â”€â”€â–º BATTERY BACKUP â”€â”€â–º PDUs â”€â”€â–º RACKS         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Compose (Dev)

```yaml
version: '3.8'

services:
  bee1:
    build: ./bee1
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=sqlite:///./data/swarmledger.db
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./data:/app/data
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  ipfs:
    image: ipfs/kubo:latest
    ports:
      - "5001:5001"
      - "8080:8080"
    volumes:
      - ipfs_data:/data/ipfs

  epoch-sealer:
    build: ./epoch-sealer
    environment:
      - DATABASE_URL=sqlite:///./data/swarmledger.db
    volumes:
      - ./data:/app/data
      - ./audit:/app/audit

volumes:
  redis_data:
  ipfs_data:
```

---

## Security Considerations

### Authentication
- All client requests signed with EIP-191
- ENS ownership verified on-chain
- No passwords, no sessions, no cookies

### Network
- Bee-1 API: Public (HTTPS via Cloudflare or nginx)
- Bee-2...N: LAN only (no public exposure)
- Redis: LAN only
- Database: Local file or LAN-only Postgres

### Data
- DICOM data: Encrypted at rest, deleted after processing
- Results: Stored on IPFS (content-addressed)
- Keys: Hardware security module (HSM) for swarmos.eth signing key

### Audit
- All jobs logged immutably
- Epochs sealed with Merkle proofs
- Full audit trail via SwarmOrb

---

## Scaling Path

### Phase 1: Single Rack (Current)
- 1 Bee-1, N Bee-2 workers
- SQLite database
- Single Redis instance

### Phase 2: Multi-Rack
- Bee-1 replicas behind load balancer
- Postgres with read replicas
- Redis Cluster

### Phase 3: Federated
- Multiple independent SwarmOS operators
- Shared epoch ledger
- Cross-operator job routing

---

## Next Steps

1. **Implement Bee-1 API** â€” FastAPI with job submission
2. **Implement Bee-2 Worker** â€” MONAI inference executor
3. **Implement Epoch Sealer** â€” Merkle + IPFS + signing
4. **Connect to SwarmOrb** â€” Index generation
5. **Deploy to rack** â€” Docker Compose

---

*This is the engine. Everything else is glass.*

ğŸâš¡
